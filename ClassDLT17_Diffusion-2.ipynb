{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YgPhHLXrZmV"
      },
      "source": [
        "https://erdem.pl/2023/11/step-by-step-visual-introduction-to-diffusion-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djzINKXhrZmb"
      },
      "outputs": [],
      "source": [
        "%pip -q install diffusers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_snippets\n"
      ],
      "metadata": {
        "id": "6aPGFG9dvDuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayd6NloXrZme",
        "outputId": "5b30d53a-6bf7-4408-f8c3-4d669afd3be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from torch_snippets import *\n",
        "from diffusers import DDPMScheduler, UNet2DModel\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torchvision\n",
        "\n",
        "device = 'cuda' # torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB3yF-JXrZmh",
        "outputId": "2e11bab2-7405-4c31-b9e3-0b85de4623f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(32),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = torchvision.datasets.MNIST(root=\"mnist/\", train=True, download=True, transform=transform)\n",
        "# dataset = Subset(dataset, [0,1,2,3,4,5,6,7])\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3RsVHWXrZmi"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "x, y = next(iter(train_dataloader))\n",
        "print('Input shape:', x.shape)\n",
        "print('Labels:', y)\n",
        "show(torchvision.utils.make_grid(x)[0], cmap='Greys')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip8RYGmVrZmj"
      },
      "outputs": [],
      "source": [
        "# Dataloader (you can mess with batch size)\n",
        "batch_size = 128\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# How many runs through the data should we do?\n",
        "\n",
        "# Create the network\n",
        "net = UNet2DModel(\n",
        "    sample_size=28,  # the target image resolution\n",
        "    in_channels=1,  # the number of input channels, 3 for RGB images\n",
        "    out_channels=1,  # the number of output channels\n",
        "    layers_per_block=1,  # how many ResNet layers to use per UNet block\n",
        "    block_out_channels=(32, 64, 128, 256),  # Roughly matching our basic unet example\n",
        "    down_block_types=(\n",
        "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
        "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
        "        \"AttnDownBlock2D\",\n",
        "        \"AttnDownBlock2D\",\n",
        "    ),\n",
        "    up_block_types=(\n",
        "        \"AttnUpBlock2D\",\n",
        "        \"AttnUpBlock2D\",\n",
        "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
        "        \"UpBlock2D\",   # a regular ResNet upsampling block\n",
        "      ),\n",
        ")\n",
        "_ = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbVGt-qArZmk"
      },
      "outputs": [],
      "source": [
        "for bx, (x, y) in enumerate(train_dataloader):\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2d_qlx6rZml",
        "outputId": "7b2cf2dc-ee40-4c60-8c88-223c8c0406d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 32, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "pred = net.conv_in(x.to(device))\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKmQsgjarZmn",
        "outputId": "2fe06d66-43e6-4f57-f953-0888d7ccc6a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 32, 32, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "pred2 = net.time_embedding(pred.to(device))\n",
        "pred2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsM4KBoLrZmo"
      },
      "outputs": [],
      "source": [
        "_ = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1coVNmVrZmp",
        "outputId": "4ba5175d-e469-4188-8bfe-0d3f08b81a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 64, 8, 8])\n"
          ]
        }
      ],
      "source": [
        "time_embedding_output = None\n",
        "\n",
        "# Define the hook function\n",
        "def get_time_embedding_output(module, input, output):\n",
        "    global time_embedding_output\n",
        "    time_embedding_output = output\n",
        "\n",
        "# Attach the hook to the time_embedding layer\n",
        "# hook = net.down_blocks[1].attentions[0].group_norm.register_forward_hook(get_time_embedding_output)\n",
        "\n",
        "hook = net.down_blocks[1].register_forward_hook(get_time_embedding_output)\n",
        "\n",
        "# Now, run your data through the model\n",
        "# Assuming 'data' is your input tensor\n",
        "_ = net(x.to(device), 78)\n",
        "\n",
        "# Detach the hook after use\n",
        "hook.remove()\n",
        "\n",
        "# 'time_embedding_output' now contains the output of the time_embedding layer\n",
        "print(time_embedding_output[1][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1fsSvG6rZmq"
      },
      "outputs": [],
      "source": [
        "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
        "\n",
        "def corrupt(xb, timesteps=None):\n",
        "  if timesteps is None:\n",
        "    timesteps = torch.randint(0, 999, (len(xb),)).long().to(device)\n",
        "  noise = torch.randn_like(xb)\n",
        "  noisy_xb = noise_scheduler.add_noise(xb, noise, timesteps)\n",
        "  return noisy_xb, timesteps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qvAasigrZmr"
      },
      "outputs": [],
      "source": [
        "_ = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Report:\n",
        "    def __init__(self, n_epochs):\n",
        "        self.n_epochs = n_epochs\n",
        "        self.losses = []\n",
        "\n",
        "    def record(self, epoch, loss, end=\"\\r\"):\n",
        "        self.losses.append(loss)\n",
        "        print(f\"Epoch {epoch:.2f}: Loss {loss:.4f}\", end=end)\n",
        "\n",
        "    def report_avgs(self, epoch):\n",
        "        avg_loss = sum(self.losses) / len(self.losses)\n",
        "        print(f\"\\nEpoch {epoch} completed. Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    def plot(self, log=False):\n",
        "        \"\"\"Plot the loss curve.\"\"\"\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.losses, label=\"Loss\", color=\"blue\")\n",
        "\n",
        "        if log:\n",
        "            plt.yscale(\"log\")  # Use log scale if specified\n",
        "\n",
        "        plt.xlabel(\"Batch Iterations\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training Loss Curve\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "7XQRQcawxZdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjwEv4yJrZmr",
        "outputId": "d92f100d-b686-4545-c02f-e5e881234036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1.00: Loss 0.0361\n",
            "Epoch 1 completed. Avg Loss: 0.0396\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# The training loop\n",
        "\n",
        "n_epochs = 1\n",
        "report = Report(n_epochs)\n",
        "loss_fn = nn.MSELoss()\n",
        "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = CosineAnnealingLR(opt, T_max=len(train_dataloader), verbose=False)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    n = len(train_dataloader)\n",
        "    for bx, (x, y) in enumerate(train_dataloader):\n",
        "        x = x.to(device)  # Data on the GPU\n",
        "        noisy_x, timesteps = corrupt(x)  # Create our noisy x\n",
        "        pred = net(noisy_x, timesteps).sample\n",
        "        loss = loss_fn(pred, x)  # How close is the output to the true 'clean' x?\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        scheduler.step()\n",
        "        report.record(epoch + ((bx + 1) / n), loss=loss.item(), end='\\r')\n",
        "    report.report_avgs(epoch + 1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68iaT8PIrZms"
      },
      "outputs": [],
      "source": [
        "report.plot(log=True)  # Log scale\n",
        "report.plot(log=False)  # Normal scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiyjxf0arZmt"
      },
      "outputs": [],
      "source": [
        "net.cpu()\n",
        "noise = torch.randn(5,1,32,32).to(net.device)\n",
        "progress = [noise[:,0]]\n",
        "\n",
        "for ts in np.logspace(np.log10(999), 0.1, 100):\n",
        "  ts = torch.Tensor([ts]).long().to(net.device)\n",
        "  noise = net(noise, ts).sample.detach().cpu()\n",
        "  noise, _ = corrupt(noise, ts)\n",
        "  progress.append(noise[:,0])\n",
        "\n",
        "print(len(progress))\n",
        "_n = 10\n",
        "subplots(torch.stack(progress[::_n]).permute(1, 0, 2, 3).reshape(-1, 32, 32), nc=11, sz=(10,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyOTePywrZmv"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcVdFF46rZmv"
      },
      "outputs": [],
      "source": [
        "# Define the Stable Diffusion XL pipeline\n",
        "pipeline2 = DiffusionPipeline.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "# Set the device for the pipeline\n",
        "pipeline2 = pipeline2.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_gQGscrrZmw"
      },
      "outputs": [],
      "source": [
        "# Setting a seed would ensure reproducibility of the experiment.\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc5R4dRhrZmx"
      },
      "outputs": [],
      "source": [
        "# Set the prompt\n",
        "prompt = \"a car in superman color\"\n",
        "# Set the negative prompt, or leave it `None` if you don't want to use it\n",
        "negative_prompt = None\n",
        "# Add the callback to the pipeline, and execute the pipeline.\n",
        "image = pipeline2(\n",
        "    prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    generator=generator,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        ")\n",
        "image.images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2KUILrYrZmx"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "\n",
        "# Define the Stable Diffusion XL pipeline\n",
        "pipeline = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "# Set the device for the pipeline\n",
        "pipeline = pipeline.to(\"cuda\")\n",
        "# uncomment the following line if you encounter OOM issues\n",
        "# pipeline.enable_sequential_cpu_offload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRCWqR0CrZmy"
      },
      "outputs": [],
      "source": [
        "# Set the prompt\n",
        "prompt = \"baby in superman dress\"\n",
        "# Set the negative prompt, or leave it `None` if you don't want to use it\n",
        "negative_prompt = None\n",
        "# Add the callback to the pipeline, and execute the pipeline.\n",
        "image = pipeline(\n",
        "    prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    generator=generator,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvtjjbSNrZmz"
      },
      "outputs": [],
      "source": [
        "image.images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfnrzZPIrZmz"
      },
      "outputs": [],
      "source": [
        "# Set the prompt\n",
        "prompt = \"baby in superman dress, photorealistic, cinematic, ultra detailed\"\n",
        "# Set the negative prompt, or leave it `None` if you don't want to use it\n",
        "negative_prompt = None\n",
        "# Add the callback to the pipeline, and execute the pipeline.\n",
        "image = pipeline(\n",
        "    prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    generator=generator,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        ")\n",
        "image.images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m93VeBEirZm0"
      },
      "outputs": [],
      "source": [
        "# Set the prompt\n",
        "prompt = \"a car in superman color, photorealistic, cinematic, ultra detailed\"\n",
        "# Set the negative prompt, or leave it `None` if you don't want to use it\n",
        "negative_prompt = None\n",
        "# Add the callback to the pipeline, and execute the pipeline.\n",
        "image = pipeline(\n",
        "    prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    generator=generator,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        ")\n",
        "image.images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z56YWJi3rZm1"
      },
      "outputs": [],
      "source": [
        "# Set the prompt\n",
        "prompt = \"an old car in a city, photorealistic, cinematic, ultra detailed, detailed face\"\n",
        "# Set the negative prompt, or leave it `None` if you don't want to use it\n",
        "negative_prompt = 'art'\n",
        "# Add the callback to the pipeline, and execute the pipeline.\n",
        "image = pipeline(\n",
        "    prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    generator=generator,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        ")\n",
        "image.images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQGMIrCarZm2"
      },
      "outputs": [],
      "source": [
        "# Set the prompt\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(12)\n",
        "prompt = \"some logo, AI based calorie meter application, ultra detailed, beautiful, atractive, modern, fat\"\n",
        "# Set the negative prompt, or leave it `None` if you don't want to use it\n",
        "negative_prompt = \"text, number, gauge\"\n",
        "# Add the callback to the pipeline, and execute the pipeline.\n",
        "image = pipeline(\n",
        "    prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    generator=generator,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        ")\n",
        "image.images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN6zrQUfrZm3"
      },
      "outputs": [],
      "source": [
        "# Set the prompt\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(20)\n",
        "prompt = \"some logo, AI based calorie meter application, ultra detailed, beautiful, atractive, modern, fat\"\n",
        "# Set the negative prompt, or leave it `None` if you don't want to use it\n",
        "negative_prompt = \"text, number, gauge\"\n",
        "# Add the callback to the pipeline, and execute the pipeline.\n",
        "image = pipeline(\n",
        "    prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    generator=generator,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        ")\n",
        "image.images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg_SqqZ_rZm3"
      },
      "outputs": [],
      "source": [
        "# Set the prompt\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(42)\n",
        "prompt = \"an old radio on the wooden table,ultra detailed, beautiful, photorealistic\"\n",
        "# Set the negative prompt, or leave it `None` if you don't want to use it\n",
        "negative_prompt = None\n",
        "# Add the callback to the pipeline, and execute the pipeline.\n",
        "image = pipeline(\n",
        "    prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    generator=generator,\n",
        "    height=512,\n",
        "    width=512,\n",
        ")\n",
        "image.images[0]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}